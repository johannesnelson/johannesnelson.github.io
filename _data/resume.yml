# If you have a `resume.json` file, copy it into `_data` and delete this file.
# If you don't have a JSON Resume you can just edit this YAML file instead.
# See also: <https://jsonresume.org/>.
basics:
  name: "Johannes Nelson"
  label: "Data Scientist, Bioacoustics Specialist, Ecologist"
  picture: /assets/img/headshot.png
  email: "johannes.nelson@gmail.com"
  phone: "(917) 444-2451"
  website: "https://johannesnelson.github.io"
  summary: >
    I am a data scientist specializing in bioacoustics and conservation analytics. 
    My research has primarily focused on the use of passive acoustic monitoring to 
    survey wildlife communities and monitor biodiversity metrics—combining traditional 
    field work techniques with deep learning/artificial intelligence for data processing 
    and analysis. My programming skills in R and Python allow me to contribute to 
    projects in a variety of ways, from building complex data analysis pipelines to 
    automating/streamlining essential processes. I also have extensive experience as an 
    educator in progressive, inquiry-based classrooms around the world. I hope to continue 
    working at the intersection of technology and ecology--using innovative deep learning 
    solutions to promote conservation and discovery.
  location:
    address: "325 Monroe St"
    postalCode: "PA 19147"
    city: "Philadelphia"
    countryCode: "US"
    region: "Pennsylvania"
  profiles:
    - network: "LinkedIn"
      username: "johannes-nelson"
      url: "https://www.linkedin.com/in/johannes-nelson-401b3a65/"
    - network: "GitHub"
      username: "johannesnelson"
      url: "https://github.com/johannesnelson"
work:
  - company: "Conservation International"
    position: "Data Scientist/Consultant"
    website: "https://piedpiper.com"
    startDate: "2023-09-30"
    endDate: "2023-12-22"
    summary: >
      During this short-term data science consultancy, I was responsible 
      for developing scripts in R to create a full data analysis pipeline
      to extract, clean/preprocess, and analyze data from tree monitoring
      surveys around the world. This monitoring program provides 
      essential metrics about Mastercard’s Priceless Planet Coalition,
      which aims to restore 100 million trees through a number of 
      major restoration projects in key areas around the globe. This 
      pipeline included scripts to 
    highlights:
      - Built complex, multi-script pipeline to extract monitoring data from Kobo Toolbox, 
      preprocess//wrangle it, correct taxonomic information using various online databases 
      and API calls, and finally to calculate key indicator metrics that will be used to 
      evaluate the success of all restoration projects in the portfolio.
      - Developed script that uses a combination of API calls and web-scraping to screen
      multiple thousands of species across dozens of organizations for potentially invasive
      species being planted.
      - Created a streamlined, semi-automated process for further classification of planting data
      into categories of native or alien using spatial occurence data from public databases and
      relevant text called and filtered from Wikipedia.
      - Built a Large Language Model powered classification agent using LangChain in Python to 
      automate the process of native//alien classifcation using intentional prompt engineering to 
      produce an organized report
volunteer:
  - organization: "Willistown Conservation Trust"
    position: "Teacher"
    website: "https://coderdojo.com/"
    startDate: "2012-01-01"
    endDate: "2013-01-01"
    summary: "Global movement of free coding clubs for young people."
    highlights:
      - "Awarded 'Teacher of the Month'"
education:
  - institution: "University of Oklahoma"
    area: "Information Technology"
    studyType: "Bachelor"
    startDate: "2011-06-01"
    endDate: "2014-01-01"
    gpa: "4.0"
    courses:
      - "DB1101 - Basic SQL"
      - "CS2011 - Java Introduction"
awards:
  - title: "Digital Compression Pioneer Award"
    date: "2014-11-01"
    awarder: "Techcrunch"
    summary: "There is no spoon."
publications:
  - name: "Video compression for 3d media"
    publisher: "Hooli"
    releaseDate: "2014-10-01"
    website: "https://en.wikipedia.org/wiki/Silicon_Valley_(TV_series)"
    summary: "Innovative middle-out compression algorithm that changes the way we store data."
skills:
  - name: "Web Development"
    level: "Master"
    keywords:
      - "HTML"
      - "CSS"
      - "Javascript"
  - name: "Compression"
    level: "Master"
    keywords:
      - "Mpeg"
      - "MP4"
      - "GIF"
languages:
  - language: "English"
    fluency: "Native speaker"
interests:
  - name: "Wildlife"
    keywords:
      - "Ferrets"
      - "Unicorns"
references:
  - name: "Erlich Bachman"
    reference: >
      It is my pleasure to recommend Richard, his performance working as a consultant for Main St.
      Company proved that he will be a valuable addition to any company.
